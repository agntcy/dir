# Copyright AGNTCY Contributors (https://github.com/agntcy)
# SPDX-License-Identifier: Apache-2.0

apiserver:
  image:
    repository: ghcr.io/agntcy/dir-apiserver
    tag: latest
    pullPolicy: IfNotPresent
    pullSecrets:
      - name: regcred

  service:
    type: NodePort # Default for local/dev - change to ClusterIP for cloud with Ingress

  # Prometheus metrics configuration
  # This section configures BOTH the application metrics server AND Kubernetes service
  # The values are automatically injected into the server configuration
  metrics:
    # Enable Prometheus metrics collection
    # Default: true (recommended for production)
    enabled: true

    # Port for Prometheus metrics endpoint
    # Used for both the application listen address and Kubernetes service port
    # Default: 9090
    port: 9090

    # ServiceMonitor for Prometheus Operator (optional)
    # Creates a ServiceMonitor resource for automatic Prometheus discovery
    serviceMonitor:
      enabled: false
      interval: 30s
      scrapeTimeout: 10s
      labels: {}

  # Routing service configuration for P2P networking
  routingService:
    # Service type for routing/P2P traffic
    # Options: ClusterIP, NodePort, LoadBalancer
    # Recommended for cloud: LoadBalancer (for stable external IP)
    # Default for local/dev: NodePort (inherits from service.type if not set)
    # Uncomment and set to LoadBalancer for production cloud deployments:
    # type: LoadBalancer

    # Cloud provider for automatic annotation configuration
    # Options: "aws", "gcp", "azure", or leave empty for no auto-configuration
    # When set, provider-specific LoadBalancer annotations are automatically applied
    # Examples:
    #   cloudProvider: "aws"    # Auto-configures AWS NLB with internet-facing scheme
    #   cloudProvider: "gcp"    # Auto-configures GCP External Load Balancer
    #   cloudProvider: "azure"  # Auto-configures Azure public Load Balancer
    # cloudProvider: ""

    # AWS-specific configuration (only used when cloudProvider: "aws")
    # aws:
    #   internal: false  # Set to true for internal NLB
    #   nlbTargetType: "instance"  # Or "ip" for IP-based targets

    # GCP-specific configuration (only used when cloudProvider: "gcp")
    # gcp:
    #   internal: false  # Set to true for internal load balancer
    #   backendConfig: ""  # Optional BackendConfig resource name

    # Azure-specific configuration (only used when cloudProvider: "azure")
    # azure:
    #   internal: false  # Set to true for internal load balancer
    #   resourceGroup: ""  # Optional resource group name

    # Optional: Static IP (must be reserved in cloud provider first)
    # loadBalancerIP: ""

    # Optional: Preserve client source IPs (recommended for P2P)
    # externalTrafficPolicy: Local

    # Optional: Fixed NodePort (only used when type is NodePort)
    # nodePort: 30555

    # Optional: Additional custom annotations (merged with provider annotations)
    # Custom annotations override provider-generated ones
    # annotations: {}

  # Authorization policy file content (separate from config)
  # This is written to authz_policies.csv file, not part of the server config struct
  authz_policies_csv: |
    p,example.org,*
    p,*,/agntcy.dir.store.v1.StoreService/Pull
    p,*,/agntcy.dir.store.v1.StoreService/PullReferrer
    p,*,/agntcy.dir.store.v1.StoreService/Lookup
    p,*,/agntcy.dir.sync.v1.SyncService/RequestRegistryCredentials

  # Server configuration (maps directly to server config.go Config struct)
  config:
    # listen_address: "0.0.0.0:8888"

    # Authentication settings (handles identity verification)
    # Supports both X.509 (X.509-SVID) and JWT (JWT-SVID) authentication
    authn:
      # Enable authentication
      enabled: false
      # Authentication mode: "x509" or "jwt"
      # - x509: Uses X.509-SVID from mutual TLS peer certificates
      # - jwt: Uses JWT-SVID from Authorization header
      mode: "x509"
      # SPIFFE Workload API socket path (injected by SPIRE agent)
      socket_path: "unix:///run/spire/agent-sockets/api.sock"
      # Expected audiences for JWT validation (only used in JWT mode)
      audiences:
        - "spiffe://example.org/dir-server"

    # Authorization settings (handles access control policies)
    # Requires authentication to be enabled first
    authz:
      # Enable authorization policies
      enabled: false

      # Path to the authorization policy file
      enforcer_policy_file_path: "/etc/agntcy/dir/authz_policies.csv"

    # Store settings for the storage backend.
    store:
      # Storage provider to use.
      provider: "oci"

      # OCI-backed store
      oci:
        # Path to a local directory that will be to hold data instead of remote.
        # If this is set to non-empty value, only local store will be used.
        # local_dir: ""

        # Cache directory to use for metadata.
        # cache_dir: ""

        # Registry address to connect to
        registry_address: ""
        
        # All data will be stored under this repo.
        # Objects are pushed as tags, manifests, and blobs.
        repository_name: ""

        # Auth credentials to use.
        auth_config:
          insecure: "true"
          # access_token: ""
          # refresh_token: ""

    # Routing settings for the peer-to-peer network.
    routing:
      # Address to use for routing
      listen_address: "/ip4/0.0.0.0/tcp/5555"

      # Path to private key file for peer ID.
      # key_path: /tmp/agntcy-dir/node.privkey

      # Nodes to use for bootstrapping of the DHT.
      # We read initial routing tables here and get introduced
      # to the network.
      # bootstrap_peers:
      #   - /ip4/1.1.1.1/tcp/1
      #   - /ip4/1.1.1.1/tcp/2

      # GossipSub configuration for efficient label announcements
      # When enabled, labels are propagated via GossipSub mesh to ALL subscribed peers
      # When disabled, falls back to DHT+Pull mechanism (higher bandwidth, limited reach)
      # Default: true (recommended for production)
      gossipsub:
        enabled: true

    # Sync configuration
    sync:
      # Authentication configuration for sync operations
      auth_config: {}

    # Publication configuration
    publication:
      # How frequently the scheduler checks for pending publications
      scheduler_interval: "1h"

      # Maximum number of publication workers running concurrently
      worker_count: 1

      # Timeout for individual publication operations
      worker_timeout: "30m"

    # Events configuration
    events:
      # Channel buffer size per subscriber
      # Larger buffers allow subscribers to fall behind temporarily without dropping events
      # Default: 100
      subscriber_buffer_size: 100

      # Enable logging when events are dropped due to slow consumers
      # Default: true
      log_slow_consumers: true

      # Enable debug logging of all published events (verbose in production)
      # Default: false
      log_published_events: false

    # Rate limiting configuration
    # Protects the server from abuse and resource exhaustion using token bucket algorithm
    ratelimit:
      # Enable rate limiting middleware
      # Default: false (disabled for development/testing)
      enabled: false

      # Global rate limit (applies to all requests regardless of client)
      # Set both to 0 to disable global limiting
      # global_rps: 0       # Requests per second (float, e.g., 1000.0)
      # global_burst: 0     # Burst capacity (int, e.g., 2000)

      # Per-client rate limit (tracked by SPIFFE ID from mTLS)
      # Default values shown below are reasonable for production
      # Set both to 0 to disable per-client limiting
      per_client_rps: 100 # Requests per second per client (float)
      per_client_burst: 200 # Burst capacity per client (int)

      # Per-method rate limit overrides (optional)
      # Allows fine-grained control over specific gRPC methods
      # Note: These can only be configured via Helm values, not environment variables
      # method_limits:
      #   "/agntcy.dir.store.v1.StoreService/CreateRecord":
      #     rps: 50      # Lower limit for expensive operations
      #     burst: 100
      #   "/agntcy.dir.store.v1.StoreService/PullRecord":
      #     rps: 200     # Higher limit for read operations
      #     burst: 400

    # Database configuration (PostgreSQL)
    # These values configure the database connection for apiserver and reconciler.
    # Users must specify ALL values explicitly - there is no auto-detection.
    # 
    # For local development (postgresql.enabled=true):
    #   Set host to the service name that will be created, e.g., "my-release-postgresql"
    #
    # For external PostgreSQL (postgresql.enabled=false):
    #   Set host to your external PostgreSQL host
    database:
      # Database type (only postgres is supported)
      type: "postgres"
      postgres:
        # PostgreSQL host address (required)
        # For local: use "<release-name>-postgresql" 
        # For external: your PostgreSQL hostname
        host: ""

        # PostgreSQL port
        port: 5432

        # Database name
        database: "dir"

        # SSL mode for PostgreSQL connection
        # Options: disable, require, verify-ca, verify-full
        ssl_mode: "disable"

    # OASF API validation configuration
    oasf_api_validation:
      # Schema URL for API-based validation
      # Default: https://schema.oasf.outshift.com (public OASF server)
      # To use the OASF instance deployed with this chart (when apiserver.oasf.enabled: true):
      #   schema_url: "http://<release-name>-ingress-controller.<namespace>.svc.cluster.local"
      # Example: schema_url: "http://dir-ingress-controller.dir-server.svc.cluster.local"
      schema_url: "https://schema.oasf.outshift.com"

      # Disable API validation (use embedded schema validation instead)
      # When true, uses embedded schemas for validation (no HTTP calls to OASF server)
      # Default: false
      disable: false

  # SPIRE configuration
  spire:
    enabled: false
    trustDomain: example.org

    # SPIRE controller className for ClusterSPIFFEID matching
    #
    # REQUIRED: The className field is mandatory for ClusterSPIFFEID resources.
    # The SPIRE controller manager uses className to match ClusterSPIFFEID resources
    # with the appropriate SPIRE installation. Without this field, the controller
    # will ignore the ClusterSPIFFEID and no workload registration will occur,
    # causing authentication failures and preventing the gRPC server from starting.
    #
    # The className must match the SPIRE installation's className.
    #
    # Default: "dir-spire" (matches standard SPIRE installation convention).
    # If your SPIRE installation uses a different className, override this value.
    # If not specified, falls back to "<namespace>-spire" (e.g., "my-namespace-spire").
    #
    # IMPORTANT: Ensure this matches your SPIRE Controller Manager's className.
    # For standard installations, SPIRE is deployed in the "spire" namespace with
    # className "dir-spire". Verify with:
    #   kubectl get deployment -n spire spire-server -o yaml | grep className
    #
    # See: https://github.com/spiffe/spire-controller-manager/blob/main/docs/clusterspiffeid-crd.md
    className: "dir-spire"

    federation: []
      # # Config: https://github.com/spiffe/spire-controller-manager/blob/main/docs/clusterfederatedtrustdomain-crd.md
      # - trustDomain: dir-cluster
      #   bundleEndpointURL: https://0.0.0.0:8081
      #   bundleEndpointProfile:
      #     type: https_web

  # Zot registry configuration (subchart)
  zot:
    # Enable Zot registry (set to false for external registries like GHCR)
    enabled: true

    # Enable default secret mounting
    mountSecret: true

    # ZOT configuration file
    configFiles:
      config.json: |-
        {
          "distSpecVersion": "1.1.1",
          "storage": {
            "rootDirectory": "/var/lib/registry"
          },
          "http": {
            "address": "0.0.0.0",
            "port": "5000",
            "auth": {
              "htpasswd": {
                "path": "/secret/htpasswd"
              }
            },
            "accessControl": {
              "adminPolicy": {
                "users": ["{{ if .Values.secrets }}{{ if .Values.secrets.ociAuth }}{{ .Values.secrets.ociAuth.username | default "admin" }}{{ else }}admin{{ end }}{{ else }}admin{{ end }}"],
                "actions": ["read", "create", "update", "delete"]
              },
              "repositories": {
                "**": {
                  "anonymousPolicy": [],
                  "defaultPolicy": ["read"]
                }
              }
            }
          },
          "log": {
            "level": "debug"
          },
          "extensions": {
            "search": {
              "enable": true
            },
            "trust": {
              "enable": true,
              "cosign": true,
              "notation": false
            }
          }
        }

    # htpasswd credentials for ZOT authentication
    secretFiles:
      htpasswd: ""

  # OASF server configuration (subchart) - OPTIONAL
  # OASF is NOT installed by default. Set enabled: true to deploy an OASF schema server instance.
  # When enabled, deploys an OASF schema server instance alongside the directory server.
  # OASF server subchart configuration
  oasf:
    enabled: false
    localDeploy: true # Creates IngressClass resource for ingress controller

    image:
      repository: ghcr.io/agntcy/oasf-server
      versions:
        - server: v0.7.2
          schema: 0.7.0
        - server: v0.8.1
          schema: 0.8.0
        - server: v1.0.0
          schema: 1.0.0
          default: true
      pullPolicy: IfNotPresent

    service:
      type: ClusterIP
      port: 8080

    config:
      server_port: 8080

    env: {}
    volumes: []
    volumeMounts: []

    ingress:
      enabled: true
      className: "nginx"
      annotations:
        nginx.ingress.kubernetes.io/ssl-redirect: "false"
      hosts:
        - host: localhost
        - host: dir-ingress-controller.dir-server.svc.cluster.local
      tls: []
      service:
        type: ClusterIP

    resources: {}

  # Secrets configuration
  # Choose ONE of two methods:
  # 1. Helm-managed secrets (secrets.*) - credentials in values.yaml
  # 2. ExternalSecrets (externalSecrets.*) - credentials synced from Vault
  #
  # Method 1: Helm-managed secrets (default)
  # Sensitive credentials are stored in Kubernetes secrets and injected as environment variables
  secrets:
    # Private key for peer-to-peer routing identity
    # If not provided, the secret will not include this key
    privKey: ""

    # Sync authentication credentials
    # Used for authenticating sync operations between nodes
    # Username defaults to "sync" if empty, password is randomly generated if empty
    syncAuth:
      username: ""
      password: ""

    # OCI registry authentication
    # Used for authenticating to the OCI-backed storage backend
    # Username defaults to "admin" if empty, password is randomly generated if empty
    ociAuth:
      username: ""
      password: ""

    # PostgreSQL authentication
    # These credentials are used for database connections.
    # When postgresql subchart is enabled, these values override postgresql.auth.* for the connection secret.
    # Username defaults to "dir", password is randomly generated if empty.
    postgresAuth:
      username: ""
      password: ""

  # Method 2: ExternalSecrets configuration
  # Syncs credentials from HashiCorp Vault (or other secret providers) using External Secrets Operator
  # When enabled, the Helm-managed secret (above) is NOT created
  externalSecrets:
    # Enable ExternalSecrets integration (default: false)
    # When true, credentials are synced from Vault instead of using values.yaml
    enabled: false

    # Vault path where credentials are stored (all credentials in one path)
    # Example: "dir_staging/dev/credentials"
    vaultPath: ""

    # ClusterSecretStore or SecretStore name to use
    # This must be pre-configured in your cluster (managed by platform team)
    secretStore: "vault-backend"

    # Secret store kind (default: ClusterSecretStore)
    # Options: ClusterSecretStore (cluster-wide) or SecretStore (namespace-scoped)
    secretStoreKind: "ClusterSecretStore"

    # Refresh interval - how often ESO syncs from Vault (default: 1h)
    refreshInterval: "1h"

    # Node identity configuration
    nodeIdentity:
      enabled: true
      # Property name in Vault secret (default: "node.privkey")
      property: "node.privkey"

    # OCI registry authentication
    ociAuth:
      enabled: true
      # Property names in Vault secret (defaults shown)
      usernameProperty: "oci-username"
      passwordProperty: "oci-password"

    # Sync authentication (shared with remote nodes)
    syncAuth:
      enabled: true
      # Property names in Vault secret (defaults shown)
      usernameProperty: "sync-username"
      passwordProperty: "sync-password"

    # PostgreSQL authentication (only used when database.type: "postgres")
    postgresAuth:
      enabled: true 
      # Property names in Vault secret (defaults shown)
      usernameProperty: "postgres-username"
      passwordProperty: "postgres-password"

  # PostgreSQL subchart configuration
  # Deploys a local PostgreSQL instance via Bitnami subchart for development/testing.
  # Set enabled: false when using an external PostgreSQL instance.
  #
  # Database connection credentials:
  # - secrets.postgresAuth.* overrides these values for the connection secret
  # - If secrets.postgresAuth is not set, these values are used directly
  #
  # Database connection settings (host, port, database, ssl_mode) must be configured
  # explicitly in config.database.postgres
  postgresql:
    enabled: true
    # image:
    #   registry: docker.io
    #   repository: bitnami/postgresql
    #   digest: sha256:c47e54a69b39aa97d4405d68ea02bf2ffe06b646748e2ddf9c761416ead6acd5
    auth:
      username: "dir"
      password: "password"  # Default password for development
      database: "dir"

  # Deployment strategy for pod updates
  # Use "Recreate" when routing PVCs are enabled to avoid
  # BadgerDB lock conflicts during updates
  #
  # Default: Recreate (prevents lock conflicts during updates)
  # - Brief downtime during updates (10-15 seconds)
  # - Required when using routing PVCs to avoid CrashLoopBackOff
  #
  # Alternative: RollingUpdate (only for stateless deployments without routing PVC)
  # - Zero-downtime updates
  # - NOT compatible with routing PVCs (will cause lock conflicts)
  strategy:
    type: Recreate

  # Reconciler configuration
  # The reconciler handles async operations including:
  # - regsync: syncs records from remote registries
  # - indexer: indexes synced records into the database for search
  # Shares the same database as the apiserver.
  reconciler:
    image:
      repository: ghcr.io/agntcy/dir-reconciler
      tag: latest
      pullPolicy: IfNotPresent

    # Reconciler configuration - all settings go here
    # This entire section is rendered directly to reconciler.config.yml
    config:
      # Database configuration (PostgreSQL)
      database:
        type: "postgres"
        postgres:
          # PostgreSQL host address
          # For local (postgresql.enabled=true): use "<release-name>-postgresql"
          # For external: your PostgreSQL hostname
          host: ""
          port: 5432
          database: "dir"
          ssl_mode: "disable"

      # Local registry configuration (for syncing)
      local_registry:
        # Registry address to connect to
        registry_address: ""
        
        # All data will be stored under this repo.
        # Objects are pushed as tags, manifests, and blobs.
        repository_name: ""

        # Auth credentials to use for syncing from the local registry.
        auth_config:
          insecure: true

      # OASF schema URL for validation
      schema_url: "https://schema.oasf.outshift.com"

      # Regsync task configuration (authn copied from config.authn by chart)
      regsync:
        enabled: true
        interval: "1h"
        timeout: "10m"

      # Indexer task configuration
      indexer:
        enabled: true
        interval: "1h"
